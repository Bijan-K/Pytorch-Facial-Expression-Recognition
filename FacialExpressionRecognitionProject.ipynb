{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOILoaziGD+l++d/8Bs/Rnx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bijan-K/Pytorch-Facial-Expression-Recognition/blob/main/FacialExpressionRecognitionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Facial Expression Classification/Recognition Project\n",
        "\n",
        "---\n",
        "Since this project was made using a Kaggle dataset, we first have to download the dataset from Kaggle API. In order to do that we need a kaggle token(Access key).\n",
        "\n",
        "Please add your Kaggle key before running the cell below."
      ],
      "metadata": {
        "id": "AjJOWTn4jW8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add your key: { display-mode: \"form\" }\n",
        "\n",
        "!touch kaggle.json\n",
        "Kaggle_Key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import json\n",
        "Kaggle_Key = json.loads(Kaggle_Key)\n",
        "with open('kaggle.json', 'w') as f:\n",
        "    json.dump(Kaggle_Key, f)"
      ],
      "metadata": {
        "id": "2wASNU_JG-aa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here I downloaded the data using the token, processed it a bit, and moved it to a designated directory:"
      ],
      "metadata": {
        "id": "2Ufm0Nn24gdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ],
      "metadata": {
        "id": "QtpRR9ATzafW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsampler\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zf = ZipFile('face-expression-recognition-dataset.zip', 'r')\n",
        "zf.extractall('/content')\n",
        "zf.close()"
      ],
      "metadata": {
        "id": "zlbJVXVy4Vrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I imported the necessary libraries for training my deeplearning model here:"
      ],
      "metadata": {
        "id": "ygBPHg1h4uhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "GIdfwWCHjhcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "defined the Device varible in order to use it conveniently later on:"
      ],
      "metadata": {
        "id": "T6s995z2-P3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking device, setting the value for later\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "GqHrI-vPkaem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the data transfomation happens, and the dataloaders are defined :"
      ],
      "metadata": {
        "id": "E4O8fFsP-XlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui3SMNYcjWf0"
      },
      "outputs": [],
      "source": [
        "# Preprocessing data\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomAffine((10)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = './images/'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'validation']}\n",
        "\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                              num_workers=2, sampler=ImbalancedDatasetSampler(image_datasets[x]))\n",
        "                    for x in ['train', 'validation']}\n",
        "\n",
        "\n",
        "train_dataloader= dataloaders[\"train\"]\n",
        "test_dataloader = dataloaders['validation']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I set the module architure and changed the last layer so it would be suitable for my project:"
      ],
      "metadata": {
        "id": "SlFOiZCQ-gTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.efficientnet_b2(progress=True)\n",
        "\n",
        "# Changing the last layer\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1408, out_features=7),\n",
        ")"
      ],
      "metadata": {
        "id": "_UBL2Z_tX-An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Criterion Funciton an Optimizer Algothrim:"
      ],
      "metadata": {
        "id": "qOqkgz_m-0oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "0BYNVrDRmM4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I made the training loop with steps, so the train function itself would be concise. As this is a rather delicate process, the types of function arguments were defined:"
      ],
      "metadata": {
        "id": "q6qox8M7_O8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "# single step of training\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "# single step of testing\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "# the root training function\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          criterion: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # The Main loop\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=criterion,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "\n",
        "\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=criterion,\n",
        "          device=device)\n",
        "\n",
        "        # progression\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )"
      ],
      "metadata": {
        "id": "hVpBOtmNY_H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Cell, with all the determined arguments:"
      ],
      "metadata": {
        "id": "CZ4x8ksj-9Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize training\n",
        "train(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, optimizer=optimizer, criterion=criterion, epochs=2, device=device)"
      ],
      "metadata": {
        "id": "RxctUrXHh3Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, I saved the model when the training was done:"
      ],
      "metadata": {
        "id": "m39-2IvW6WCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the Model\n",
        "torch.save(model.state_dict(), './trained_model.pt')"
      ],
      "metadata": {
        "id": "wnKi03vmHhVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}